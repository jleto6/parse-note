<h1>Pipeline Hazards, Forwarding, and Exception Handling in MIPS Processors</h1>
<p style="color:whitesmoke;">
<strong>Load/store instructions</strong> require <strong>data memory access</strong> during execution. In the context of a pipelined CPU, if the <strong>data memory</strong> is shared with the <strong>instruction memory</strong>, a <strong>structural hazard</strong> can occur: the hardware cannot simultaneously fetch the next instruction and service a data access. When this situation arises, the <strong>instruction fetch</strong> stage must stall for that cycle, which is called a <strong>pipeline bubble</strong>. A <strong>pipeline bubble</strong> is an empty slot in the pipeline, manifesting as a loss in throughput. To avoid such hazards and maintain pipeline efficiency, it is essential to provide separate <strong>instruction memory</strong> and <strong>data memory</strong>, sometimes accomplished through separate <strong>instruction and data caches</strong>.
</p>
<!-- END_SECTION -->

<p style="color:whitesmoke;">
<strong>Data hazards</strong> arise when an instruction depends on the completion of a data access or computation in a previous instruction. For example, if the pipeline executes <code style="color:#00aaff; font-family: Menlo, Monaco, 'Courier New', monospace;">add $s0, $t0, $t1</code> followed immediately by <code style="color:#00aaff; font-family: Menlo, Monaco, 'Courier New', monospace;">sub $t2, $s0, $t3</code>, the second instruction needs the result of the <code style="color:#00aaff; font-family: Menlo, Monaco, 'Courier New', monospace;">add</code> before it is available in the register file. This scenario demonstrates a <strong>read-after-write (RAW) hazard</strong>, central to pipelined processor design.
</p>
<!-- END_SECTION -->

<p style="color:whitesmoke;">
<strong>Forwarding</strong>, also known as <strong>bypassing</strong>, addresses many <strong>data hazards</strong> by using the result of a computation as soon as it is produced, even before it is written back to the register file. This is made possible by adding extra connections in the <strong>datapath</strong> that can transfer results directly from the output of one pipeline stage (such as the EX or MEM stage) to the input of another (such as the EX stage of the following instruction). As a result, the pipeline does not need to wait for the value to be stored in a register before using it in a subsequent instruction.
</p>
<!-- END_SECTION -->

<p style="color:whitesmoke;">
In forwarding, the <strong>result</strong> from an earlier instruction is passed forward to a later instruction as soon as it is available. For example, the value computed by the ALU can be sent directly to the next instruction that needs it, minimizing pipeline stalls and improving throughput. Forwarding introduces additional <strong>multiplexers</strong> and <strong>control logic</strong> to select the correct data source.
</p>
<!-- END_SECTION -->

<p style="color:whitesmoke;">
Despite <strong>forwarding</strong>, certain hazards—specifically the <strong>load-use data hazard</strong>—cannot always be avoided. This occurs when an instruction immediately uses a value being loaded from memory by a preceding instruction. Since the load instruction receives the data only in the MEM stage, but the dependent instruction needs it for execution in the next cycle, the pipeline must stall.
</p>
<!-- END_SECTION -->

<p style="color:whitesmoke;">
A <strong>pipeline stall</strong>, or <strong>bubble</strong>, is implemented by injecting a <strong>nop</strong> (no operation) instruction into the pipeline. Practically, this is achieved by forcing all control values associated with valid operations in the pipeline register (such as the <code style="color:#00aaff; font-family: Menlo, Monaco, 'Courier New', monospace;">ID/EX</code> register) to 0, causing the pipeline to behave as if a <code style="color:#00aaff; font-family: Menlo, Monaco, 'Courier New', monospace;">nop</code> is present.
</p>
<!-- END_SECTION -->

<p style="color:whitesmoke;">
In a diagram of the <strong>MIPS pipeline</strong>, a bubble is depicted as being inserted at a pipeline stage—stalling the advance of subsequent instructions. Other representations may illustrate a stall by halting the flow of instruction between stages or by introducing explicit <code style="color:#00aaff; font-family: Menlo, Monaco, 'Courier New', monospace;">nop</code> operations, with or without explicit bubbles. The precise implementation depends on the control and data path design.
</p>
<!-- END_SECTION -->

<p style="color:whitesmoke;">
To minimize the impact of stalls, <strong>code scheduling</strong> can be used. This technique involves reordering instructions during compilation to avoid immediate use of a load result in the next dependent operation, thus allowing other independent instructions to fill the potential bubble slot. For example:
<pre style="color:whitesmoke; background:#23272e; font-family: Menlo, Monaco, 'Courier New', monospace;">
lw   $t1, 0($t0)
lw   $t2, 4($t0)
add  $t3, $t1, $t2
sw   $t3, 12($t0)
lw   $t4, 8($t0)
add  $t5, $t1, $t4
sw   $t5, 16($t0)
</pre>
In the version above, stalls occur because of immediate load-use dependencies. By rescheduling:
<pre style="color:whitesmoke; background:#23272e; font-family: Menlo, Monaco, 'Courier New', monospace;">
lw   $t1, 0($t0)
lw   $t2, 4($t0)
lw   $t4, 8($t0)
add  $t3, $t1, $t2
sw   $t3, 12($t0)
add  $t5, $t1, $t4
sw   $t5, 16($t0)
</pre>
the number of cycles needed for execution is reduced (from 13 to 11), demonstrating how careful instruction order selection reduces pipeline stalls.
</p>
<!-- END_SECTION -->

<p style="color:whitesmoke;">
<strong>Control hazards</strong> refer to situations where the pipeline cannot determine the correct sequence of instructions to fetch due to control flow instructions (e.g., branches or jumps). A <strong>branch hazard</strong> arises because the proper instruction to fetch next depends on the outcome of a branching instruction, which may not be resolved until the instruction is well into the pipeline (e.g., in the MEM stage), thus forcing a stall.
</p>
<!-- END_SECTION -->

<p style="color:whitesmoke;">
One approach to control hazards is to <strong>stall on branch</strong>: the pipeline does not fetch the next instruction until the branch outcome is known. However, this leads to lost cycles and decreased throughput, especially in longer pipelines.
</p>
<!-- END_SECTION -->

<p style="color:whitesmoke;">
An improved method is <strong>branch prediction</strong>. For pipelines that cannot resolve the branch early, predicting branch behavior helps reduce stall penalties. In the MIPS pipeline, <strong>static branch prediction</strong> is often used: the processor predicts that branches will not be taken and fetches the next sequential instruction as normal. Only if this prediction is wrong (i.e., the branch is taken and was not predicted as such) are the subsequent fetched instructions flushed (removed) from the pipeline, and the correct target instruction is fetched.
</p>
<!-- END_SECTION -->

<p style="color:whitesmoke;">
If a branch is determined as taken in the MEM stage, all instructions that entered after the branch must be <strong>flushed</strong> from the pipeline. This is accomplished by setting their control signals to 0, effectively injecting <code style="color:#00aaff; font-family: Menlo, Monaco, 'Courier New', monospace;">nop</code> instructions. The cost is minimized if branches are not often taken.
</p>
<!-- END_SECTION -->

<p style="color:whitesmoke;">
The effectiveness of <strong>static prediction</strong> depends on branch behavior. If a branch is correctly predicted (not taken as expected), the pipeline proceeds without penalty. If incorrect, the penalty is limited to flushing the extra instructions. If branches are not taken half the time, and flushing costs little, this approach can halve the penalty associated with control hazards.
</p>
<!-- END_SECTION -->

<p style="color:whitesmoke;">
<strong>Static branch prediction</strong> is based on expected patterns: predicting loop (backward) branches as taken and forward branches as not taken often reflects real control flow, such as in loops and conditional statements. This can be encoded in the processor’s control logic.
</p>
<!-- END_SECTION -->

<p style="color:whitesmoke;">
In more advanced and <strong>superscalar pipelines</strong>, <strong>dynamic branch prediction</strong> becomes necessary due to increased branch penalty. A <strong>branch history table (BHT)</strong> uses the address of recent branches as an index to record whether the branch was previously taken or not. The processor refers to this table, predicts the branch, and fetches accordingly. If the prediction is incorrect, the pipeline is flushed and the correct path is resumed, with the BHT updated for future predictions.
</p>
<!-- END_SECTION -->

<p style="color:whitesmoke;">
A simple <strong>1-bit predictor</strong> tracks only the last branch outcome. This can be suboptimal for nested branches, such as inner and outer loops, causing two mispredictions per loop: once when the inner loop exits, and again on its next first iteration.
</p>
<!-- END_SECTION -->

<p style="color:whitesmoke;">
A <strong>2-bit predictor</strong> improves upon the 1-bit model by requiring two consecutive mispredictions before changing its prediction state. This increases robustness, especially in the scenario of loops, by maintaining the prediction unless the outcome truly changes pattern.
</p>
<!-- END_SECTION -->

<p style="color:whitesmoke;">
The <strong>delayed decision</strong> model (delayed branching) allows executing one or more instructions after a branch regardless of the branch outcome. The MIPS architecture, for instance, may execute the instruction following the branch during the branch’s execution, often called the <strong>branch delay slot</strong>. For example:
<pre style="color:whitesmoke; background:#23272e; font-family: Menlo, Monaco, 'Courier New', monospace;">
add $4, $5, $6
beq $1, $2, 40
</pre>
The next instruction may execute regardless of whether the branch is taken. Delayed branch slots are rarely more than one instruction, and longer delays require more elaborate prediction hardware.
</p>
<!-- END_SECTION -->

<p style="color:whitesmoke;">
Reducing the branch delay is possible by optimizing the datapath. Many branches rely on simple operand comparisons (e.g., register equality), which can be computed with minimal hardware (a few gates over the ALU). More complex branches may take two instructions, such as using <code style="color:#00aaff; font-family: Menlo, Monaco, 'Courier New', monospace;">slt</code> (set on less than) followed by a conditional branch. By moving the hardware for the branch outcome (such as a target address adder and register comparator) to the <strong>ID stage</strong>, the penalty from branches can in many cases be reduced to only a single-cycle penalty.
</p>
<!-- END_SECTION -->

<p style="color:whitesmoke;">
<strong>Pipelining</strong> fundamentally increases performance by improving instruction throughput—multiple instructions are in execution concurrently, with parallel progress through different pipeline stages. The <strong>latency</strong> for each instruction, defined as the time from initiation to completion, remains unchanged, but more instructions complete per unit time. However, the pipeline's efficiency is subject to various <strong>hazards</strong>: structural, data, and control hazards. These hazards must be addressed to realize pipelining’s potential. Notably, the <strong>instruction set architecture (ISA)</strong> design can either facilitate or hinder effective pipelined implementations.
</p>
<!-- END_SECTION -->

<p style="color:whitesmoke;">
<strong>Exceptions</strong> and <strong>interrupts</strong> represent unexpected events that require deviation from the normal instruction sequence. An <strong>exception</strong> arises within the CPU itself, caused by events like illegal opcodes, arithmetic overflow, or explicit system calls (e.g., <code style="color:#00aaff; font-family: Menlo, Monaco, 'Courier New', monospace;">syscall</code>). An <strong>interrupt</strong>, in contrast, originates outside the CPU, typically from I/O devices requiring attention.
</p>
<!-- END_SECTION -->

<p style="color:whitesmoke;">
In MIPS, <strong>exceptions</strong> are managed by the <strong>System Control Coprocessor (CP0)</strong>. When an exception occurs, the processor saves the <strong>program counter (PC)</strong> of the offending or interrupted instruction to the <strong>Exception Program Counter (EPC)</strong>. Simultaneously, information about the problem is stored in a <strong>Status register</strong>—for example: <code style="color:#00aaff; font-family: Menlo, Monaco, 'Courier New', monospace;">0000</code> for undefined instructions, <code style="color:#00aaff; font-family: Menlo, Monaco, 'Courier New', monospace;">0180</code> for arithmetic overflow. The processor then jumps to an exception handler.
</p>
<!-- END_SECTION -->

<p style="color:whitesmoke;">
An <strong>exception handler</strong> performs several actions:
<ol>
  <li>Reads the cause of the exception, transferring control to the relevant handler routine.</li>
  <li>Determines the requisite action, which may be corrective or may call for program termination.</li>
  <li>If the exception is <strong>restartable</strong>, takes corrective steps and uses the EPC to resume program execution.</li>
  <li>If non-restartable, terminates the program and reports the error using the saved EPC as diagnostic information.</li>
</ol>
</p>
<!-- END_SECTION -->

<p style="color:whitesmoke;">
Handling exceptions in a pipeline introduces a new class of control hazards. For example, if an arithmetic overflow occurs in the EX stage on <code style="color:#00aaff; font-family: Menlo, Monaco, 'Courier New', monospace;">add $1, $2, $1</code>, care must be taken to:
<ol>
  <li>Prevent $1 from being overwritten with an invalid result.</li>
  <li>Allow prior instructions to complete to preserve correct state.</li>
  <li>Flush the <code style="color:#00aaff; font-family: Menlo, Monaco, 'Courier New', monospace;">add</code> instruction and all younger instructions from the pipeline.</li>
  <li>Set the <strong>Cause</strong> and <strong>EPC</strong> registers in the CP0 coprocessor.</li>
  <li>Transfer control to the designated exception handler.</li>
</ol>
This approach shares similarities with the hardware mechanisms developed for handling mispredicted branches, leveraging much of the same flushing and control logic.
</p>
<!-- END_SECTION -->

<p style="color:whitesmoke;">
Because pipelining overlaps multiple instructions, <strong>multiple exceptions</strong> could arise in the same clock cycle. A simple policy is to handle only the exception from the earliest instruction in the pipeline and to flush all subsequent instructions. This maintains exception handling order and preserves state consistency.
</p>
<!-- END_SECTION -->

<p style="color:whitesmoke;">
Several <strong>fallacies</strong> exist regarding pipelining. While the conceptual model is straightforward, the practical implementation is complex. A major challenge lies in reliable detection and management of <strong>data hazards</strong>. Additionally, pipelining is not independent of technology; advances in transistor density have made complex pipelines feasible where they were once impractical. Instruction set and pipeline design must take technical constraints and future hardware improvements into account.
</p>
<!-- END_SECTION -->

<p style="color:whitesmoke;">
There are significant <strong>pitfalls</strong> to avoid. Poorly designed ISAs can complicate pipelining, as seen in complex instruction sets such as VAX or IA-32, which require significant hardware overhead for pipeline support. Complications may arise from numerous addressing modes, irregular instruction formats, and register side effects. <strong>Delayed branches</strong> in advanced pipelines can lead to long delay slots, which are difficult to manage for both hardware and compilers.
</p>
<!-- END_SECTION -->

<p style="color:whitesmoke;">
The interaction between the <strong>instruction set architecture (ISA)</strong> and <strong>datapath and control</strong> is reciprocal: ISA features influence implementation choices, while limitations of the datapath and control inform ISA design decisions. <strong>Pipelining</strong> dramatically increases instruction throughput but does not reduce individual instruction latency. Mitigating hazards—structural, data, control—and providing robust exception and interrupt management are crucial for efficient, correct execution.
</p>
<!-- END_SECTION -->