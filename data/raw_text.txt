Block Diagram
1 scan
Combinatinal vs Sequential
1 scan
Block Diagram
1 scan
Combinatinal vs Sequential
1 scan

Logic Gates
3 scans
Adder
4 scans
Logic Gates
3 scans
Adder
4 scans

### Transcription of Handwritten Notes

---

**Floating Point Arithmetic**

Real numbers are called "float" values in computing. Floating point arithmetic is the method computers use to handle real numbers.

Floats are represented using the IEEE 754 standard, which increases accuracy by storing numbers using the principle of normalized scientific notation.

IEEE 754 encodes floating-point numbers using 3 components: a sign bit, an exponent, and a mantissa. To store numbers effectively, IEEE 754 defines normalized form, meaning the first digit before the decimal is always 1 in binary (1.xxxx * 2^y).

Since this leading 1 is always present, IEEE 754 does not store it explicitly (this is called the hidden bit). Instead, only the fractional part is stored, allowing the mantissa to hold more precision within the available bits.

This differs from standard scientific notation where the leading digit is always explicitly written (e.g., 1.23 x 10^2 in decimal). By enforcing normalization and using a hidden bit, IEEE allows efficient storage and greater accuracy in floating-point precision.

A floating-point number is always represented as: 
- **Sign Bit (s):** Determines whether the number is positive (0) or negative (1).
- **Exponent (e):** Determines how much to shift the binary point (stored using a biased representation).
- **Mantissa (m):** Represents the precision (with an assumed 1).

**Exponential Notation**

e.g., The following are equivalent representations of 1.234
- 1.234 * 10^0
- 12.34 * 10^-1
- 0.1234 * 10^1

**IEEE 754 Standard**

- **Single Precision:** 32 bits, consisting of...
- **Double Precision:** 64 bits, consisting of...

**Floating Point: Normalized Scientific Notation**

- **Single Precision (32 bits):** 1 sign bit, 8 exponent bits, 23 mantissa bits
- **Double Precision (64 bits):** 1 sign bit, 11 exponent bits, 52 mantissa bits

Note: Floating points can represent...

---

This transcription captures the notes' structure and key points. If you need detailed explanations or illustrations about floating point arithmetic, feel free to ask!
**Exceptions and Interrupts**

"Unexpected" events such as exceptions and interrupts require altering control flow. Exceptions occur within the CPU, e.g., undefined opcodes or overflows, while interrupts come from external I/O controllers. For example, an I/O controller might send an interrupt when a disk finishes reading data, prompting the CPU to switch context to a waiting process.

In MIPS, exceptions are handled by the System Control Coprocessor (CP0), saving the program counter in the Exception Program Counter (EPC), indicating problems in the status register.

The exception handling process involves reading the cause, transferring control to the appropriate handler, and determining required actions. If resolvable, corrective measures are taken; otherwise, the program is terminated, using the EPC to correct errors.

Pipeline exceptions introduce another form of control hazard. For example, overflow during the execution stage triggers premature register overwrite, impacting previous instructions and hampering control handling. The approach is similar to handling mispredicted branches: freeze instruction execution in pipelines, simulating exceptions as breaks in the pipeline flow until execution can safely suspend before handling a typical overflow.

Challenges arise when instructions depend on accelerator, cache, or bus hazards. Pitfalls in pipelining usually come from poorly chosen ISAs, where compilers can mismanage pipelining order due to issues like unusual memory dependencies or architectures unexpectedly change registers, adding instruction fault depth on memory.
**Transcription of Handwritten Notes:**

---

**CPU Performance**

A clock cycle is a single tick of the CPU's internal clock, during which a basic instruction can be carried out. The CPU uses this regular pulse to synchronize and control the execution of instructions.

**Clock Period:** The time duration of one cycle  
**Clock Frequency:** How many cycles occur per second

**CPU Time:** Amount of CPU clock cycles x Clock Cycle Time (Period)  
**CPU Time:** Amount of CPU clock cycles / Clock Rate (Frequency)

Execution Time is further defined by instruction count, the total number of instructions a program executes, and Cycles Per Instruction (CPI). The CPI reflects how different instructions consume varied cycles which reflects the CPU's design and is affected by the instruction mix (proportion of different types of instructions).

The comparison of CPU performance involves the equation:  
CPU Time = Instruction Count x CPI x Clock Cycle  
This formula is important because it connects various core components of performance, offering insight into how efficiency can be optimized.

Components of performance include:  
- **Instruction Count:** The number of instructions executed by the CPU.  
- **Clock Cycle:** Typical development is part of system specifications, it defines the duration of one cycle of clock signals within the CPU.  
- **Cycles Per Instruction (CPI):** An average measurement reflecting the mean number of cycles taken for instructions. This depends on the hardware design, which is the frequency and type of combination of instructions being executed.

CPI in more detail highlights the unique areas where each instruction type frequency and cycle cost contribute to the overall CPI.

---

**CPI Example**

[There appears to be a diagram or chart here, but it's not described in the notes.]


Here is the transcription of the handwritten notes:

---

Writing

A cache must manage how data is written. This involves deciding whether update main memory immediately or delay a write, and how to handle write miss. These choices affect consistency, performance and capacity.

When the CPU performs a store instruction, it writes data to memory. With a cache in place, this raises the issue of whether the write goes to cache, main memory, or both. If data is only written to the cache, main memory may have a different value, causing inconsistency.

Write Strategy:
- Write through updates both cache and main memory simultaneously. It’s simple but slow. A write buffer is often used to reduce stalls.
- Write back only updates the data in the cache during a write hit; main memory is not updated right away. Each block is marked with a dirty bit to indicate if it has been modified since being loaded from memory. If a block is clean, it can be replaced without writing to memory. If a block is "dirty," it must be written back to memory before being replaced.
Direct Caching

Associativity

The image you provided is a blank white square. There's no diagram, chart, graph, or handwritten notes to analyze or transcribe. If you intended to provide a specific image, please try uploading it again.
Control Signals

Datapath with Control 
Examples

Control Signal Overview

**Canonical Forms**

Canonical forms are standardized ways to express Boolean functions, making it easier to build and simplify circuits. The 2 main types are Sum of Products (SOP) and Product of Sums (POS), which describe when a circuit should output a 1 or a 0.

SOP expressions are built from minterms, which represent truth table cases where the output is 1, while POS expressions are built from maxterms, which represent rows where the output is 0.

**Sum of Products**:
- SOP uses minterms:
  - Look at rows where F=1 in the truth table.
  - Each 1 becomes an ANDed term (A'B'C).
  - OR all AND terms together.
  - For example, if F=1 at (A=0, B=1, C=0), the minterm is A'BC'.

**Product of Sums**:
- POS uses maxterms:
  - Look at rows where F=0 in the truth table.
  - Each 0 becomes an ORed term (A+B+C').
  - AND all the OR terms together.
  - For example, if F=0 at (A=1, B=0, C=1), the maxterm is A+B'C.
**Title: Binary Conversions**

**Text Transcription:**

* In the modern world, we use decimal, or base 10, notation to represent integers. We can represent numbers using any base b, where b is a positive integer greater than 1.

**Base 10:**
- For example, 965, this can be translated as: 9∙10^2 + 6∙10^1 + 5∙10^0

**Base b:**
- Let b be a positive integer greater than 1. Then if n is a positive integer, it can be expressed uniquely in the form, where k is a nonnegative integer and a_k, a_(k-1), ..., a_1, a_0 are nonnegative integers less than b.

- This representation of n is called the base b expansion of n and can be denoted by (a_k a_(k-1) ... a_1 a_0)_b.

**Binary Operations:**
- Computers represent integers and do arithmetic with binary (base 2) expansions of integers. In these expansions, the digits used are 0 and 1.

- Example: What is the decimal expansion of the integer that has (11011)_2 as its binary expansion?
  
  Solution: (11011)_2
  
  - = 1∙2^4 + 1∙2^3 + 0∙2^2 + 1∙2^1 + 1∙2^0
  - = 16 + 8 + 0 + 2 + 1
  - = 27

**Base Conversion:**
- To construct the base b expansion of the integer n, divide n by b to obtain a quotient and remainder: n = b∙q_0 + a_0, 0 ≤ a_0 < b.
  
  - The remainder, a_0, is the right-most digit in the base b expansion of n.
  
  - Next, divide q_0 by b to get q_0 = b∙q_1 + a_1, 0 ≤ a_1 < b.
  
  - Continue this process, the 2nd right-most digit in the base b expansion of n.
  
  - Continue by successively dividing the quotient by b, obtaining the new quotient and remainder as the remainder. The process terminates when the quotient is 0. 

The notes describe the methods and concepts behind converting numbers between different bases, specifically focusing on binary (base 2) and its use in computers. It includes an example of how to convert a binary number to decimal and the process of converting a decimal number to another base.
The image contains typed notes on the topic of "Caches" related to computing. Here's a transcription of the text:

---

**Caches**

In an ideal computing system there would be unlimited fast memory access. However such a system is not practically achievable. Instead a memory hierarchy provides the illusion of large amount of fast memory by organizing different types of storage to optimize speed and access.

The principal of locality refers to the observation that programs tend to access only a small portion of their address space at any given time, which is crucial to optimizing the memory hierarchy. There are two main types of locality:

1. *Temporal locality*: Refers to the tendency of programs to access the same memory locations repeatedly within a short period. For example, instructions in loops and induction variables.
2. *Spatial locality*: Denotes the likelihood of accessing memory locations close together in physical address. This occurs in sequently instruction access and accessing array data. 

Understanding these principals helps in designing cache systems and hardware to enhance performance.

**Memory Hierarchy Levels**
- Cache levels include smaller, faster memory that is closer to the processor.
- *Data moves through* these layers of memory in temporal and spatial reference. Frequently used data and instruction are copied from primary storage (like SSD or HDD) to main memory (DRAM), and then smaller, faster cache (SRAM) near the CPU.
- Data is moved between levels in blocks, which may multiple words units. This is a key concept in managing memory transitions.
- Caches are used to store frequently accessed data closer to the processor, minimizing access times and improving speed.

Cache memory is the closest level of memory hierarchy to the CPU. It serves as high retrieval the most frequently or recently accessed data.

A hit occurs when accessed data is present in the upper memory-level, resulting in faster access times. A miss occurs if the accessed data is not in the upper memory level, requiring data retrieval from lower levels, which is slower.

---
Cache Cache on hit ond mss A is” quick» bt miss con chs For exanpe, if the cache miss cote is ord the data cache mas rate is 47, wilh base CPI of 2 ond a mis of (00 we cam the mss as Glows = mar 0.02 +100=2 = D-cache mss Cth 36% oF loads and 6.0¢ = Total 346 Ths in 0 CPT of 5.44 2+ wis Tn an ideal with a cache (no mises), He CPU cn al the CPT of 2. the CPL ths He CPU veld be 2.72 fe te menny Tf we CPL by halt, the CPL beams 4.44. Menory remain a of the overall CPI, shoving how the CPL aloe

