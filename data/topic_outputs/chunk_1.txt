process a miss
• Creates a stall in the pipeline

Cache Miss (Instruction Memory)
1. Send the original PC value (current PC – 4) to the memory.
2. Instruct main memory to perform a read and wait for the memory to 
complete its access.
3. Write the cache entry, putting the data from memory in the data portion of 
the entry, writing the upper bits of the address (from the ALU) into the tag 
field, and turning the valid bit on.
4. Restart the instruction execution at the first step, which will refetch the 
instruction, this time finding it in the cache.

Cache Miss
• Stall until the data is fetched from memory
• Instruction cache miss
• Restart instruction fetch
• Data cache miss
• Complete data access

Cache Miss
• Misses are classified into three different types
• Compulsory (cold start)
• First access to a piece of data
• Cannot be avoided
• Capacity
• Working set of program is larger than cache size
• Not enough room to cache a locality
• Conflict
• collisions, multiple blocks competing for the same space
• Misses may be reduced by changing the associativity of the cache

Cache Organizations
• Direct mapped
• Set associative
• Fully associative

Fully Associative
• A block in memory may be associated with any entry in the cache
• Requires all entries to be searched at once
• Comparator per entry (expensive)

N-way Set Associative
• Each block may go to n locations
• Each set contains n entries
• Block number determines which set
• (Block number) modulo (#Sets in cache)
• Search all entries in a given set at once
• n comparators (less expensive)

Associative Cache Example

Associativity
• All cache organizations are a variation of set associativity.
• Direct mapped: 1-way set associative
• Fully associative: m-way associative where m is the number of blocks in the 
cache

Spectrum of Associativity
• For a cache with 8 entries

Set Associative Cache Organization

Replacement Policy
• Direct mapped: no choice
• Set associative
• Prefer non-valid entry, if there is one
• Otherwise, choose among entries in the set
• Least-recently used (LRU)
• Choose the one unused for the longest time
• Simple for 2-way, manageable for 4-way, too hard beyond that
• Random
• Gives approximately the same performance as LRU for high associativity

Associativity Example
• Compare 4-block caches
• Direct mapped, 2-way set associative, fully associative
• Block access sequence: 0, 8, 0, 6, 8
• Direct mapped
Block 
address
Cache 
index
Hit/miss
Cache content after access
0
1
2
3

Associativity Example
• Compare 4-block caches
• Direct mapped, 2-way set associative, fully associative
• Block access sequence: 0, 8, 0, 6, 8
• Direct mapped
Block 
address
Cache 
index
Hit/miss
Cache content after access
0
1
2
3
0
0
miss
Mem[0]

Associativity Example
• Compare 4-block caches
• Direct mapped, 2-way set associative, fully associative
• Block access sequence: 0, 8, 0, 6, 8
• Direct mapped
Block 
address
Cache 
index
Hit/miss
Cache content after access
0
1
2
3
0
0
miss
Mem[0]
8
0
miss
Mem[8]

Associativity Example
• Compare 4-block caches
• Direct mapped, 2-way set associative, fully associative
• Block access sequence: 0, 8, 0, 6, 8
• Direct mapped
Block 
address
Cache 
index
Hit/miss
Cache content after access
0
1
2
3
0
0
miss
Mem[0]
8
0
miss
Mem[8]
0
0
miss
Mem[0]

Associativity Example
• Compare 4-block caches
• Direct mapped, 2-way set associative, fully associative
• Block access sequence: 0, 8, 0, 6, 8
• Direct mapped
Block 
address
Cache 
index
Hit/miss
Cache content after access
0
1
2
3
0
0
miss
Mem[0]
8
0
miss
Mem[8]
0
0
miss
Mem[0]
6
2
miss
Mem[0]
Mem[6]

Associativity Example
• Compare 4-block caches
• Direct mapped, 2-way set associative, fully associative
• Block access sequence: 0, 8, 0, 6, 8
• Direct mapped
Block 
address
Cache 
index
Hit/miss
Cache content after access
0
1
2
3
0
0
miss
Mem[0]
8
0
miss
Mem[8]
0
0
miss
Mem[0]
6
2
miss
Mem[0]
Mem[6]
8
0
miss
Mem[8]
Mem[6]

Associativity Example
• Compare 4-block caches
• 